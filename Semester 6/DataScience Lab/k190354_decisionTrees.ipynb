{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a4f220e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~ DATASET # 01 ~~~~~~~~~~~~~~~~~~~~~~~`\n",
      "\n",
      "\t\t1) 10 x 10 FOLD CV: \n",
      "\n",
      "\n",
      "Iris data using gini without pruning: \n",
      "Accuracy: 0.9427142857142857 \tStandard Deviation: 0.05600232826387718\n",
      "\n",
      "Iris data using gini with pruning: \n",
      "Accuracy: 0.9414761904761905 \tStandard Deviation: 0.06340416733444378\n",
      "\n",
      "Iris data using Entropy without pruning: \n",
      "Accuracy: 0.9447142857142857 \tStandard Deviation: 0.05276007818739597\n",
      "\n",
      "Iris data using Entropy with pruning: \n",
      "Accuracy: 0.9360952380952381 \tStandard Deviation: 0.05726249380946407\n",
      "\n",
      "\t\t2) Holdout Approach: \n",
      "\n",
      "\n",
      "Iris data using gini without pruning: \n",
      "Accuracy: 0.9417777777777778 \tStandard Deviation: 0.029106869920058568\n",
      "\n",
      "Iris data using gini with pruning: \n",
      "Accuracy: 0.9435555555555556 \tStandard Deviation: 0.031335697310350796\n",
      "\n",
      "Iris data using Entropy without pruning: \n",
      "Accuracy: 0.9382222222222222 \tStandard Deviation: 0.02941067245611681\n",
      "\n",
      "Iris data using Entropy with pruning: \n",
      "Accuracy: 0.9395555555555555 \tStandard Deviation: 0.030320102934774298\n",
      "~~~~~~~~~~~~~~~~~~~~~ DATASET # 01 ~~~~~~~~~~~~~~~~~~~~~~~`\n",
      "\n",
      "\t\t1) 10 x 10 FOLD CV: \n",
      "\n",
      "\n",
      "Haberman data using gini without pruning: \n",
      "Accuracy: 0.6458172043010754 \tStandard Deviation: 0.0783703383416457\n",
      "\n",
      "Haberman data using gini with pruning: \n",
      "Accuracy: 0.7038817204301075 \tStandard Deviation: 0.06156341629508611\n",
      "\n",
      "Haberman data using Entropy without pruning: \n",
      "Accuracy: 0.6381935483870969 \tStandard Deviation: 0.08414533012748744\n",
      "\n",
      "Haberman data using Entropy with pruning: \n",
      "Accuracy: 0.7121935483870969 \tStandard Deviation: 0.06881186471220309\n",
      "\n",
      "2) Holdout Approach: \n",
      "\n",
      "\n",
      "Haberman data using gini without pruning: \n",
      "Accuracy: 0.6510869565217391 \tStandard Deviation: 0.04275208791151551\n",
      "\n",
      "Haberman data using gini with pruning: \n",
      "Accuracy: 0.7215217391304348 \tStandard Deviation: 0.0313066122369421\n",
      "\n",
      "Haberman data using Entropy without pruning: \n",
      "Accuracy: 0.6460869565217391 \tStandard Deviation: 0.04584122347163283\n",
      "\n",
      "Haberman data using Entropy with pruning: \n",
      "Accuracy: 0.7015217391304348 \tStandard Deviation: 0.04120181782470879\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedShuffleSplit, RepeatedKFold, train_test_split\n",
    "\n",
    "print(\"~~~~~~~~~~~~~~~~~~~~~ DATASET # 01 ~~~~~~~~~~~~~~~~~~~~~~~`\\n\")\n",
    "print(\"\\t\\t1) 10 x 10 FOLD CV: \\n\")\n",
    "dataset = pd.read_csv(\"iris.data\")\n",
    "\n",
    "Gini = DecisionTreeClassifier(criterion = \"gini\")\n",
    "CV = RepeatedKFold(n_splits = 10, n_repeats = 10, random_state = 1)\n",
    "array = dataset.values\n",
    "X=array[:,0:4]\n",
    "Y=array[:, 4]\n",
    "\n",
    "Acc_n_Std = cross_val_score(Gini, X, Y, scoring='accuracy', cv=CV, n_jobs = -1)\n",
    "print(\"\\nIris data using gini without pruning: \")\n",
    "print( 'Accuracy:', np.mean(Acc_n_Std), '\\tStandard Deviation:', np.std(Acc_n_Std))\n",
    "Gini_P = DecisionTreeClassifier( criterion='gini', ccp_alpha = 0.015)\n",
    "CV = RepeatedKFold(n_splits = 10, n_repeats = 10, random_state = 1)\n",
    "array = dataset.values\n",
    "X=array[:,0:4]\n",
    "Y=array[:,4]\n",
    "Acc_n_Std = cross_val_score(Gini_P, X, Y, scoring='accuracy', cv=CV, n_jobs = -1)\n",
    "print(\"\\nIris data using gini with pruning: \")\n",
    "print('Accuracy:', np.mean(Acc_n_Std), '\\tStandard Deviation:', np.std(Acc_n_Std))\n",
    "\n",
    "Entropy = DecisionTreeClassifier( criterion='entropy' )\n",
    "CV = RepeatedKFold(n_splits = 10, n_repeats = 10, random_state = 1)\n",
    "X=array[:,0:4]\n",
    "Y=array[:, 4]\n",
    "Acc_n_Std = cross_val_score(Entropy, X, Y, scoring='accuracy', cv=CV, n_jobs = -1)\n",
    "print(\"\\nIris data using Entropy without pruning: \")\n",
    "print( 'Accuracy:', np.mean(Acc_n_Std), '\\tStandard Deviation:', np.std(Acc_n_Std))\n",
    "\n",
    "Entropy_P = DecisionTreeClassifier( criterion='entropy', ccp_alpha = 0.015)\n",
    "CV = RepeatedKFold(n_splits = 10, n_repeats = 10, random_state = 1)\n",
    "X=array[:,0:4]\n",
    "Y=array[:, 4]\n",
    "Acc_n_Std = cross_val_score(Entropy_P, X, Y, scoring='accuracy', cv=CV, n_jobs = -1)\n",
    "print(\"\\nIris data using Entropy with pruning: \")\n",
    "print( 'Accuracy:', np.mean(Acc_n_Std), '\\tStandard Deviation:', np.std(Acc_n_Std))\n",
    "\n",
    "print(\"\\n\\t\\t2) Holdout Approach: \\n\")\n",
    "Gini = DecisionTreeClassifier(criterion = \"gini\")\n",
    "CV2 = StratifiedShuffleSplit(n_splits=100, test_size=0.3, random_state=0)\n",
    "array = dataset.values\n",
    "X=array[:,0:4]\n",
    "Y=array[:, 4]\n",
    "Acc_n_Std = cross_val_score(Gini, X, Y, scoring='accuracy', cv=CV2, n_jobs = -1)\n",
    "print(\"\\nIris data using gini without pruning: \")\n",
    "print( 'Accuracy:', np.mean(Acc_n_Std), '\\tStandard Deviation:', np.std(Acc_n_Std))\n",
    "\n",
    "Gini_P = DecisionTreeClassifier( criterion='gini', ccp_alpha = 0.015)\n",
    "CV2 = StratifiedShuffleSplit(n_splits=100, test_size=0.3, random_state=0)\n",
    "array = dataset.values\n",
    "X=array[:,0:4]\n",
    "Y=array[:,4]\n",
    "Acc_n_Std = cross_val_score(Gini_P, X, Y, scoring='accuracy', cv=CV2, n_jobs = -1)\n",
    "print(\"\\nIris data using gini with pruning: \")\n",
    "print( 'Accuracy:', np.mean(Acc_n_Std), '\\tStandard Deviation:', np.std(Acc_n_Std))\n",
    "\n",
    "Entropy = DecisionTreeClassifier( criterion='entropy' )\n",
    "CV2 = StratifiedShuffleSplit(n_splits=100, test_size=0.3, random_state=0)\n",
    "X=array[:,0:4]\n",
    "Y=array[:, 4]\n",
    "Acc_n_Std = cross_val_score(Entropy, X, Y, scoring='accuracy', cv=CV2, n_jobs = -1)\n",
    "print(\"\\nIris data using Entropy without pruning: \")\n",
    "print( 'Accuracy:', np.mean(Acc_n_Std), '\\tStandard Deviation:', np.std(Acc_n_Std))\n",
    "\n",
    "Entropy_P = DecisionTreeClassifier( criterion='entropy', ccp_alpha = 0.015)\n",
    "CV2 = StratifiedShuffleSplit(n_splits=100, test_size=0.3, random_state=0)\n",
    "X=array[:,0:4]\n",
    "Y=array[:, 4]\n",
    "Acc_n_Std = cross_val_score(Entropy_P, X, Y, scoring='accuracy', cv=CV2, n_jobs = -1)\n",
    "print(\"\\nIris data using Entropy with pruning: \")\n",
    "print( 'Accuracy:', np.mean(Acc_n_Std), '\\tStandard Deviation:', np.std(Acc_n_Std))\n",
    "\n",
    "\n",
    "print(\"~~~~~~~~~~~~~~~~~~~~~ DATASET # 01 ~~~~~~~~~~~~~~~~~~~~~~~`\\n\")\n",
    "print(\"\\t\\t1) 10 x 10 FOLD CV: \\n\")\n",
    "dataset2 = pd.read_csv(\"haberman.data\")\n",
    "\n",
    "Gini = DecisionTreeClassifier(criterion = \"gini\")\n",
    "CV = RepeatedKFold(n_splits = 10, n_repeats = 10, random_state = 1)\n",
    "array2 = dataset2.values\n",
    "X=array2[:,0:3]\n",
    "Y=array2[:, 3]\n",
    "Acc_n_Std = cross_val_score(Gini, X, Y, scoring='accuracy', cv=CV, n_jobs = -1)\n",
    "print(\"\\nHaberman data using gini without pruning: \")\n",
    "print( 'Accuracy:', np.mean(Acc_n_Std), '\\tStandard Deviation:', np.std(Acc_n_Std))\n",
    "\n",
    "Gini_P = DecisionTreeClassifier( criterion='gini', ccp_alpha = 0.015)\n",
    "CV = RepeatedKFold(n_splits = 10, n_repeats = 10, random_state = 1)\n",
    "array2 = dataset2.values\n",
    "X=array2[:,0:3]\n",
    "Y=array2[:,3]\n",
    "Acc_n_Std = cross_val_score(Gini_P, X, Y, scoring='accuracy', cv=CV, n_jobs = -1)\n",
    "print(\"\\nHaberman data using gini with pruning: \")\n",
    "print( 'Accuracy:', np.mean(Acc_n_Std), '\\tStandard Deviation:', np.std(Acc_n_Std))\n",
    "\n",
    "Entropy = DecisionTreeClassifier( criterion='entropy' )\n",
    "CV = RepeatedKFold(n_splits = 10, n_repeats = 10, random_state = 1)\n",
    "X=array2[:,0:3]\n",
    "Y=array2[:, 3]\n",
    "Acc_n_Std = cross_val_score(Entropy, X, Y, scoring='accuracy', cv=CV, n_jobs = -1)\n",
    "print(\"\\nHaberman data using Entropy without pruning: \")\n",
    "print( 'Accuracy:', np.mean(Acc_n_Std), '\\tStandard Deviation:', np.std(Acc_n_Std))\n",
    "\n",
    "Entropy_P = DecisionTreeClassifier( criterion='entropy', ccp_alpha = 0.015)\n",
    "CV = RepeatedKFold(n_splits = 10, n_repeats = 10, random_state = 1)\n",
    "X=array2[:,0:3]\n",
    "Y=array2[:, 3]\n",
    "Acc_n_Std = cross_val_score(Entropy_P, X, Y, scoring='accuracy', cv=CV, n_jobs = -1)\n",
    "print(\"\\nHaberman data using Entropy with pruning: \")\n",
    "print( 'Accuracy:', np.mean(Acc_n_Std), '\\tStandard Deviation:', np.std(Acc_n_Std))\n",
    "\n",
    "print(\"\\n\\t\\t2) Holdout Approach: \\n\")\n",
    "\n",
    "\n",
    "Gini = DecisionTreeClassifier(criterion = \"gini\")\n",
    "CV2 = StratifiedShuffleSplit(n_splits=100, test_size=0.3, random_state=0)\n",
    "array2 = dataset2.values\n",
    "X=array2[:,0:3]\n",
    "Y=array2[:, 3]\n",
    "Acc_n_Std = cross_val_score(Gini, X, Y, scoring='accuracy', cv=CV2, n_jobs = -1)\n",
    "print(\"\\nHaberman data using gini without pruning: \")\n",
    "print( 'Accuracy:', np.mean(Acc_n_Std), '\\tStandard Deviation:', np.std(Acc_n_Std))\n",
    "\n",
    "Gini_P = DecisionTreeClassifier( criterion='gini', ccp_alpha = 0.015)\n",
    "CV2 = StratifiedShuffleSplit(n_splits=100, test_size=0.3, random_state=0)\n",
    "array2 = dataset2.values\n",
    "X=array2[:,0:3]\n",
    "Y=array2[:,3]\n",
    "Acc_n_Std = cross_val_score(Gini_P, X, Y, scoring='accuracy', cv=CV2, n_jobs = -1)\n",
    "print(\"\\nHaberman data using gini with pruning: \")\n",
    "print( 'Accuracy:', np.mean(Acc_n_Std), '\\tStandard Deviation:', np.std(Acc_n_Std))\n",
    "\n",
    "Entropy = DecisionTreeClassifier( criterion='entropy' )\n",
    "CV2 = StratifiedShuffleSplit(n_splits=100, test_size=0.3, random_state=0)\n",
    "X=array2[:,0:3]\n",
    "Y=array2[:, 3]\n",
    "Acc_n_Std = cross_val_score(Entropy, X, Y, scoring='accuracy', cv=CV2, n_jobs = -1)\n",
    "print(\"\\nHaberman data using Entropy without pruning: \")\n",
    "print( 'Accuracy:', np.mean(Acc_n_Std), '\\tStandard Deviation:', np.std(Acc_n_Std))\n",
    "\n",
    "Entropy_P = DecisionTreeClassifier( criterion='entropy', ccp_alpha = 0.015)\n",
    "CV2 = StratifiedShuffleSplit(n_splits=100, test_size=0.3, random_state=0)\n",
    "X=array2[:,0:3]\n",
    "Y=array2[:, 3]\n",
    "Acc_n_Std = cross_val_score(Entropy_P, X, Y, scoring='accuracy', cv=CV2, n_jobs = -1)\n",
    "print(\"\\nHaberman data using Entropy with pruning: \")\n",
    "print( 'Accuracy:', np.mean(Acc_n_Std), '\\tStandard Deviation:', np.std(Acc_n_Std))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5dd303",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
